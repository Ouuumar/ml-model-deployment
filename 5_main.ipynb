{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    import os.path as path\n",
    "    from pickle import load, dump\n",
    "    import warnings\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    from sklearn import metrics\n",
    "    from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "    from xgboost import XGBClassifier\n",
    "\n",
    "    from urllib.parse import urlparse\n",
    "    import mlflow\n",
    "    import mlflow.sklearn\n",
    "\n",
    "    import logging\n",
    "\n",
    "    logging.basicConfig(level=logging.WARN)\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    def model_input():\n",
    "        model = input(\"\\n============Give model name, xgBoost.pkl, GradientBoosting.pkl, randomForest.pkl==============\\n\")\n",
    "        return str(model)\n",
    "\n",
    "    def eval_score(X_test):\n",
    "        \"\"\"\n",
    "        X_test : test dataset, y_pred : prediction made,  : name of the model desired\n",
    "        return score of the model\n",
    "        \"\"\"\n",
    "        # clf = load_model(model_input())\n",
    "        clf = load_model()\n",
    "        preds = make_prediction(X_test)\n",
    "        return metrics.accuracy_score(X_test, preds)\n",
    "\n",
    "    def make_prediction(X_test):\n",
    "        clf = load_model()\n",
    "        return clf.predict(X_test)\n",
    "\n",
    "    def load_model():\n",
    "        \"\"\"\n",
    "         : name of the model desired\n",
    "        return the model desired\n",
    "        \"\"\"\n",
    "        model = model_input\n",
    "        return load(open(path.join('6_models', \"{}\").format(\"xgBoost.pkl\"), 'rb'))\n",
    "\n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "        \"\"\"\n",
    "        main loop to train, predict and score our models\n",
    "        \"\"\"\n",
    "        # model = model_input()\n",
    "\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        np.random.seed(40)\n",
    "\n",
    "        print(\"\\nInitializing the program\\n...\")\n",
    "\n",
    "        X_test = pd.read_csv(path.join(\"3_X_fitted_dataframe\", \"X_test_scaled.csv\"))\n",
    "        X_train = pd.read_csv(path.join(\"3_X_fitted_dataframe\", \"X_train_scaled.csv\"))\n",
    "        y_train = pd.read_csv(path.join('4_y_dataframe', 'y_train.csv'))   \n",
    "        y_test = pd.read_csv(path.join('4_y_dataframe', 'y_test.csv'))   \n",
    "\n",
    "        try:\n",
    "            print(\"\\nData loaded\\n...\")\n",
    "        except Exception as e:\n",
    "            logger.exception(\n",
    "                \"Unable to download training & test CSV, check your internet connection. Error: %s\", e\n",
    "            )\n",
    "\n",
    "        with mlflow.start_run():\n",
    "            clf = load_model()\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            predicted = clf.predict(X_test)\n",
    "\n",
    "            score = eval_score(X_test)\n",
    "            mlflow.log_param(\"accuracy\", score)\n",
    "            print(\"\\nlogged accuracy\\n...\")\n",
    "\n",
    "            tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "\n",
    "            # Model registry does not work with file store\n",
    "            if tracking_url_type_store != \"file\":\n",
    "                # Register the model\n",
    "                mlflow.sklearn.log_model(clf, \"model\", registered_=str())\n",
    "                print(\"\\nmodel registered\\n <3\")\n",
    "            else:\n",
    "                mlflow.sklearn.log_model(clf, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data loaded\n",
      "\n",
      "[19:54:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e2451e044033ce079ff6ade6403154a5557f0feb2168df54e5a5df33c651b5ee"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
